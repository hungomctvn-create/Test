import cv2
import numpy as np
from gtts import gTTS
import pygame
import time
import os
import threading
import urllib.request

# Bi·∫øn to√†n c·ª•c ƒë·ªÉ theo d√µi tr·∫°ng th√°i
is_speaking = False
face_detected = False
program_running = True

# Kh·ªüi t·∫°o YOLO v·ªõi OpenCV (thay th·∫ø Ultralytics)
class YOLODetector:
    def __init__(self):
        self.net = None
        self.output_layers = []
        self.classes = []
        self.load_yolo_model()
    
    def download_yolo_files(self):
        """T·∫£i c√°c file YOLO c·∫ßn thi·∫øt"""
        files = {
            "yolov3.cfg": "https://github.com/pjreddie/darknet/raw/master/cfg/yolov3.cfg",
            "coco.names": "https://github.com/pjreddie/darknet/raw/master/data/coco.names"
        }
        
        print("ƒêang t·∫£i c√°c file YOLO...")
        for filename, url in files.items():
            if not os.path.exists(filename):
                print(f"ƒêang t·∫£i {filename}...")
                urllib.request.urlretrieve(url, filename)
        
        # T·∫£i weights (file l·ªõn)
        if not os.path.exists("yolov3.weights"):
            print("ƒêang t·∫£i yolov3.weights (248MB)...")
            weights_url = "https://pjreddie.com/media/files/yolov3.weights"
            urllib.request.urlretrieve(weights_url, "yolov3.weights")
    
    def load_yolo_model(self):
        """T·∫£i m√¥ h√¨nh YOLO"""
        try:
            # Ki·ªÉm tra v√† t·∫£i file n·∫øu c·∫ßn
            if not all(os.path.exists(f) for f in ["yolov3.weights", "yolov3.cfg", "coco.names"]):
                self.download_yolo_files()
            
            # T·∫£i m·∫°ng YOLO
            self.net = cv2.dnn.readNet("yolov3.weights", "yolov3.cfg")
            
            # L·∫•y t√™n c√°c layer
            layer_names = self.net.getLayerNames()
            self.output_layers = [layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]
            
            # T·∫£i danh s√°ch classes
            with open("coco.names", "r") as f:
                self.classes = [line.strip() for line in f.readlines()]
            
            print("M√¥ h√¨nh YOLO ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
            return True
        except Exception as e:
            print(f"L·ªói khi t·∫£i m√¥ h√¨nh YOLO: {e}")
            return False
    
    def detect_people(self, frame):
        """Ph√°t hi·ªán ng∆∞·ªùi trong frame"""
        if self.net is None:
            return []
        
        height, width, channels = frame.shape
        
        # Chu·∫©n b·ªã input cho YOLO
        blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
        self.net.setInput(blob)
        
        # Ch·∫°y forward pass
        outs = self.net.forward(self.output_layers)
        
        # X·ª≠ l√Ω k·∫øt qu·∫£
        people_boxes = []
        confidences = []
        
        for out in outs:
            for detection in out:
                scores = detection[5:]
                class_id = np.argmax(scores)
                confidence = scores[class_id]
                
                # Class 0 l√† 'person' trong COCO dataset
                if class_id == 0 and confidence > 0.5:
                    center_x = int(detection[0] * width)
                    center_y = int(detection[1] * height)
                    w = int(detection[2] * width)
                    h = int(detection[3] * height)
                    
                    x = int(center_x - w / 2)
                    y = int(center_y - h / 2)
                    
                    people_boxes.append([x, y, w, h])
                    confidences.append(float(confidence))
        
        # √Åp d·ª•ng Non-Maximum Suppression
        if people_boxes:
            indexes = cv2.dnn.NMSBoxes(people_boxes, confidences, 0.5, 0.4)
            if len(indexes) > 0:
                return [people_boxes[i] for i in indexes.flatten()]
        
        return []

# Kh·ªüi t·∫°o detector
yolo_detector = YOLODetector()

def check_camera_devices():
    """Ki·ªÉm tra c√°c thi·∫øt b·ªã camera c√≥ s·∫µn"""
    available_cameras = []
    for i in range(5):  # Ki·ªÉm tra 5 thi·∫øt b·ªã ƒë·∫ßu ti√™n
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            ret, _ = cap.read()
            if ret:
                available_cameras.append(i)
            cap.release()
    return available_cameras

def initialize_camera(camera_id=0):  # Thay ƒë·ªïi t·ª´ 1 th√†nh 0
    """Kh·ªüi t·∫°o camera v·ªõi ID c·ª• th·ªÉ"""
    cap = cv2.VideoCapture(camera_id)
    if not cap.isOpened():
        available_cameras = check_camera_devices()
        if available_cameras:
            print(f"Kh√¥ng th·ªÉ m·ªü camera {camera_id}. C√°c camera c√≥ s·∫µn: {available_cameras}")
            print(f"Th·ª≠ m·ªü camera {available_cameras[0]}...")
            cap = cv2.VideoCapture(available_cameras[0])
        else:
            print("L·ªói: Kh√¥ng t√¨m th·∫•y camera n√†o. Ki·ªÉm tra k·∫øt n·ªëi USB ho·∫∑c driver.")
            print("üí° H∆Ø·ªöNG D·∫™N KH·∫ÆC PH·ª§C:")
            print("1. Ki·ªÉm tra USB camera ƒë√£ c·∫Øm ch∆∞a: lsusb | grep -i camera")
            print("2. C√†i ƒë·∫∑t v4l2loopback: sudo apt install v4l2loopback-dkms")
            print("3. T·∫°o virtual camera: sudo modprobe v4l2loopback devices=1")
            print("4. Ki·ªÉm tra devices: ls -la /dev/video*")
            return None
    
    # ƒê·∫∑t ƒë·ªô ph√¢n gi·∫£i (t√πy ch·ªçn, gi·∫£m t·∫£i cho RPi)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    return cap

# H√†m t·∫°o v√† ph√°t √¢m thanh ch√†o
def speak_greeting():
    global is_speaking
    try:
        is_speaking = True
        text = "Xin ch√†o! R·∫•t vui ƒë∆∞·ª£c g·∫∑p b·∫°n!"
        tts = gTTS(text=text, lang='vi')
        
        # ƒê·∫£m b·∫£o th∆∞ m·ª•c t·∫°m t·ªìn t·∫°i
        temp_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "temp")
        os.makedirs(temp_dir, exist_ok=True)
        
        # L∆∞u file v√†o th∆∞ m·ª•c t·∫°m
        greeting_file = os.path.join(temp_dir, "greeting.mp3")
        tts.save(greeting_file)
        
        # Ph√°t √¢m thanh
        pygame.mixer.init()
        pygame.mixer.music.load(greeting_file)
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            time.sleep(0.1)
        pygame.mixer.quit()
        
        # X√≥a file t·∫°m sau khi ph√°t xong
        if os.path.exists(greeting_file):
            os.remove(greeting_file)
            
        is_speaking = False
    except Exception as e:
        print(f"L·ªói khi t·∫°o ho·∫∑c ph√°t √¢m thanh: {e}")
        is_speaking = False

def speak_in_thread():
    """Ph√°t √¢m thanh trong m·ªôt lu·ªìng ri√™ng bi·ªát"""
    if not is_speaking:
        threading.Thread(target=speak_greeting, daemon=True).start()

def draw_status(frame, fps=0):
    """Hi·ªÉn th·ªã tr·∫°ng th√°i tr√™n khung h√¨nh"""
    # V·∫Ω n·ªÅn cho vƒÉn b·∫£n tr·∫°ng th√°i
    cv2.rectangle(frame, (10, 10), (300, 110), (0, 0, 0), -1)
    
    # Hi·ªÉn th·ªã tr·∫°ng th√°i khu√¥n m·∫∑t
    face_status = "ƒê√£ ph√°t hi·ªán khu√¥n m·∫∑t" if face_detected else "Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t"
    face_color = (0, 255, 0) if face_detected else (0, 0, 255)
    cv2.putText(frame, face_status, (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, face_color, 2)
    
    # Hi·ªÉn th·ªã tr·∫°ng th√°i √¢m thanh
    speak_status = "ƒêang ph√°t √¢m thanh" if is_speaking else "S·∫µn s√†ng ch√†o"
    speak_color = (255, 165, 0) if is_speaking else (255, 255, 255)
    cv2.putText(frame, speak_status, (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, speak_color, 2)
    
    # Hi·ªÉn th·ªã FPS
    cv2.putText(frame, f"FPS: {fps:.1f}", (20, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
    
    # Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n
    cv2.putText(frame, "Nh·∫•n 'q' ƒë·ªÉ tho√°t", (20, 115), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

def main():
    global face_detected, program_running
    
    print("ƒêang kh·ªüi t·∫°o h·ªá th·ªëng nh·∫≠n d·∫°ng ng∆∞·ªùi...")
    
    # Kh·ªüi t·∫°o camera
    cap = initialize_camera()
    if cap is None:
        print("Kh√¥ng th·ªÉ kh·ªüi t·∫°o camera. Tho√°t ch∆∞∆°ng tr√¨nh.")
        return
    
    print("Camera ƒë√£ s·∫µn s√†ng. Nh·∫•n 'q' ƒë·ªÉ tho√°t.")
    
    # Bi·∫øn ƒë·∫øm FPS
    fps_counter = 0
    fps_start_time = time.time()
    current_fps = 0
    
    # Bi·∫øn theo d√µi th·ªùi gian ph√°t hi·ªán cu·ªëi c√πng
    last_detection_time = 0
    detection_cooldown = 3  # 3 gi√¢y gi·ªØa c√°c l·∫ßn ch√†o
    
    while program_running:
        ret, frame = cap.read()
        if not ret:
            print("Kh√¥ng th·ªÉ ƒë·ªçc khung h√¨nh t·ª´ camera.")
            break
        
        # L·∫≠t khung h√¨nh theo chi·ªÅu ngang (t√πy ch·ªçn)
        frame = cv2.flip(frame, 1)
        
        # Ph√°t hi·ªán ng∆∞·ªùi trong khung h√¨nh
        people_boxes = yolo_detector.detect_people(frame)
        
        # C·∫≠p nh·∫≠t tr·∫°ng th√°i ph√°t hi·ªán
        current_time = time.time()
        if people_boxes:
            face_detected = True
            
            # V·∫Ω bounding box cho m·ªói ng∆∞·ªùi ƒë∆∞·ª£c ph√°t hi·ªán
            for box in people_boxes:
                x, y, w, h = box
                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                cv2.putText(frame, "Person", (x, y - 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # Ph√°t √¢m thanh ch√†o n·∫øu ƒë√£ ƒë·ªß th·ªùi gian cooldown
            if (current_time - last_detection_time) > detection_cooldown:
                speak_in_thread()
                last_detection_time = current_time
        else:
            face_detected = False
        
        # T√≠nh to√°n FPS
        fps_counter += 1
        if fps_counter >= 30:  # C·∫≠p nh·∫≠t FPS m·ªói 30 khung h√¨nh
            fps_end_time = time.time()
            current_fps = fps_counter / (fps_end_time - fps_start_time)
            fps_counter = 0
            fps_start_time = fps_end_time
        
        # V·∫Ω th√¥ng tin tr·∫°ng th√°i
        draw_status(frame, current_fps)
        
        # Hi·ªÉn th·ªã khung h√¨nh
        cv2.imshow('Nh·∫≠n d·∫°ng ng∆∞·ªùi - YOLO', frame)
        
        # Ki·ªÉm tra ph√≠m b·∫•m
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            program_running = False
            break
    
    # D·ªçn d·∫πp
    cap.release()
    cv2.destroyAllWindows()
    print("Ch∆∞∆°ng tr√¨nh ƒë√£ k·∫øt th√∫c.")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nCh∆∞∆°ng tr√¨nh b·ªã ng·∫Øt b·ªüi ng∆∞·ªùi d√πng.")
        program_running = False
    except Exception as e:
        print(f"L·ªói kh√¥ng mong mu·ªën: {e}")
    finally:
        cv2.destroyAllWindows()